---
description: Design and optimize prompts for LLM applications
---

# Prompt Engineering

I will help you design and optimize prompts for LLM applications.

## Guardrails
- Test prompts with various inputs
- Consider edge cases and misuse
- Keep prompts maintainable
- Version control your prompts

## Steps

### 1. Understand the Task
Ask clarifying questions:
- What should the LLM do?
- What inputs will it receive?
- What format should output be in?
- Any constraints or guardrails needed?

### 2. Design Prompt Structure
Include key elements:
- **Role**: Define who the AI is
- **Context**: Provide background
- **Instructions**: Clear task description
- **Examples**: Few-shot learning
- **Output Format**: Specify structure

### 3. Write the Prompt
Best practices:
- Be specific and clear
- Use delimiters for sections
- Provide examples
- Specify constraints

### 4. Test and Iterate
- Test with various inputs
- Check for edge cases
- Refine based on failures
- A/B test variations

### 5. Optimize
Improve performance:
- Reduce token usage
- Improve consistency
- Add guardrails
- Handle errors gracefully

## Principles
- Clarity > Cleverness
- Test with real-world examples
- Document prompt versions
- Consider failure modes
